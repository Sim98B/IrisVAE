{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca59bdf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T16:03:05.096745Z",
     "start_time": "2024-12-06T16:03:05.091953Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5834b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T16:00:44.954204Z",
     "start_time": "2024-12-06T16:00:44.887712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    \n",
    "print(f'Actual device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7647be8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T16:00:45.694008Z",
     "start_time": "2024-12-06T16:00:45.679699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = load_iris()['data']\n",
    "X\n",
    "min_max = MinMaxScaler()\n",
    "X = min_max.fit_transform(X)\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b083ac9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T16:00:46.274878Z",
     "start_time": "2024-12-06T16:00:46.244685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4])\n",
      "tensor([[0.6667, 0.5417, 0.7966, 1.0000],\n",
      "        [0.1111, 0.5000, 0.0508, 0.0417],\n",
      "        [0.6667, 0.4167, 0.7119, 0.9167],\n",
      "        [0.2500, 0.2917, 0.4915, 0.5417],\n",
      "        [0.1944, 0.5833, 0.1017, 0.1250],\n",
      "        [0.5000, 0.4167, 0.6610, 0.7083],\n",
      "        [0.1667, 0.4583, 0.0847, 0.0000],\n",
      "        [0.3056, 0.7917, 0.0508, 0.1250],\n",
      "        [0.9444, 0.3333, 0.9661, 0.7917],\n",
      "        [0.3333, 0.1667, 0.4576, 0.3750],\n",
      "        [0.3333, 0.2500, 0.5763, 0.4583],\n",
      "        [0.2222, 0.7500, 0.1017, 0.0417],\n",
      "        [0.1667, 0.2083, 0.5932, 0.6667],\n",
      "        [0.8611, 0.3333, 0.8644, 0.7500],\n",
      "        [0.3889, 0.3333, 0.5254, 0.5000],\n",
      "        [0.1667, 0.4167, 0.0678, 0.0417],\n",
      "        [0.6111, 0.5000, 0.6949, 0.7917],\n",
      "        [0.7222, 0.4583, 0.6949, 0.9167],\n",
      "        [0.1944, 0.4167, 0.1017, 0.0417],\n",
      "        [0.0278, 0.5000, 0.0508, 0.0417],\n",
      "        [0.5556, 0.5417, 0.6271, 0.6250],\n",
      "        [0.7222, 0.4583, 0.7458, 0.8333],\n",
      "        [0.3333, 0.1250, 0.5085, 0.5000],\n",
      "        [0.3056, 0.4167, 0.5932, 0.5833],\n",
      "        [0.2778, 0.7083, 0.0847, 0.0417],\n",
      "        [0.6667, 0.4583, 0.5763, 0.5417],\n",
      "        [0.1944, 0.5000, 0.0339, 0.0417],\n",
      "        [0.5556, 0.1250, 0.5763, 0.5000],\n",
      "        [0.6667, 0.2083, 0.8136, 0.7083],\n",
      "        [0.5833, 0.3333, 0.7797, 0.8333],\n",
      "        [0.4167, 0.2500, 0.5085, 0.4583],\n",
      "        [0.8333, 0.3750, 0.8983, 0.7083]])\n"
     ]
    }
   ],
   "source": [
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype = torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "dataset = IrisDataset(X)\n",
    "dataloader = DataLoader(dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(f'{batch.shape}\\n{batch}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5fecc5c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:05:48.335292Z",
     "start_time": "2024-12-06T17:05:48.331090Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in dataloader:\n",
    "    batch = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "370c1312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T17:16:59.935403Z",
     "start_time": "2024-12-06T17:16:59.918186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-7.7135e-03, -5.9712e-02, -1.2771e-01,  1.5375e-01],\n",
       "         [-1.4391e-04, -4.3714e-02, -1.1657e-01,  1.4200e-01],\n",
       "         [ 2.3427e-04,  7.2498e-03, -1.2600e-01,  1.0298e-01],\n",
       "         [-1.3898e-02, -4.1719e-02, -9.8445e-02,  1.4800e-01],\n",
       "         [ 1.1355e-01, -3.0341e-02, -1.0669e-01,  1.2169e-01],\n",
       "         [ 4.1417e-02, -3.6572e-02, -8.9376e-02,  9.5198e-02],\n",
       "         [-8.0407e-03, -8.0758e-02, -1.4783e-01,  1.3479e-01],\n",
       "         [ 1.6625e-02, -3.0793e-02, -1.2535e-01,  1.2252e-01],\n",
       "         [ 2.2204e-02, -1.4559e-02, -1.2521e-01,  1.0978e-01],\n",
       "         [ 9.5967e-03, -5.5966e-02, -8.8129e-02,  1.3020e-01],\n",
       "         [ 2.0876e-02, -1.7032e-02, -1.6937e-01,  1.3410e-01],\n",
       "         [ 2.3369e-02, -8.9876e-03, -1.4439e-01,  9.6828e-02],\n",
       "         [ 7.1979e-02, -5.0008e-02, -1.1610e-01,  1.5891e-01],\n",
       "         [-1.8326e-02, -3.1170e-02, -1.1865e-01,  1.0396e-01],\n",
       "         [ 3.4209e-02,  2.2012e-02, -1.4198e-01,  1.0398e-01],\n",
       "         [ 2.4021e-02, -7.9709e-02, -1.1930e-01,  8.7155e-02],\n",
       "         [-3.4654e-02, -7.1759e-03, -1.4867e-01,  1.0367e-01],\n",
       "         [ 7.4110e-02,  1.1043e-02, -9.6396e-02,  1.2186e-01],\n",
       "         [-1.7094e-02, -1.7758e-02, -1.2323e-01,  1.1828e-01],\n",
       "         [ 1.4450e-02, -2.2499e-02, -1.2920e-01,  1.2180e-01],\n",
       "         [ 1.5444e-02, -4.6604e-02, -1.3545e-01,  1.5735e-01],\n",
       "         [-1.2284e-02, -3.6501e-02, -1.3018e-01,  1.4669e-01]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.0982, -0.0402,  0.1007, -0.0149],\n",
       "         [-0.1126, -0.0408,  0.0986, -0.0452],\n",
       "         [-0.1130,  0.0063,  0.0864, -0.0629],\n",
       "         [-0.1415, -0.0571,  0.1093, -0.0298],\n",
       "         [-0.1501, -0.0348,  0.1004, -0.0688],\n",
       "         [-0.1106, -0.0768,  0.0822, -0.1056],\n",
       "         [-0.0802, -0.0290,  0.0941, -0.0202],\n",
       "         [-0.1148,  0.0012,  0.1155, -0.0282],\n",
       "         [-0.1501, -0.0505,  0.0370, -0.0258],\n",
       "         [-0.1248, -0.0177, -0.0118, -0.0602],\n",
       "         [-0.1185, -0.0859,  0.1440, -0.0072],\n",
       "         [-0.1363, -0.0685,  0.0659, -0.0556],\n",
       "         [-0.1539, -0.0434,  0.0835, -0.0444],\n",
       "         [-0.0897, -0.0602,  0.0653, -0.0173],\n",
       "         [-0.1174, -0.0551,  0.0818, -0.0699],\n",
       "         [-0.1604,  0.0207,  0.0771, -0.0644],\n",
       "         [-0.1040, -0.0492,  0.0954, -0.0653],\n",
       "         [-0.1157, -0.0230,  0.0553, -0.0375],\n",
       "         [-0.1029, -0.0690,  0.0680, -0.0466],\n",
       "         [-0.0975, -0.0436,  0.0593, -0.0430],\n",
       "         [-0.0891, -0.0604,  0.0561, -0.0304],\n",
       "         [-0.1186, -0.0407,  0.0731, -0.0455]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.0719,  0.0820,  0.0875,  ...,  0.0599, -0.0984,  0.0364],\n",
       "         [ 0.0714,  0.0877,  0.0709,  ...,  0.0759, -0.0357, -0.0089],\n",
       "         [ 0.0074,  0.0263,  0.1099,  ..., -0.0093, -0.0133,  0.0947],\n",
       "         ...,\n",
       "         [ 0.0965,  0.0974,  0.0376,  ..., -0.0541, -0.0744,  0.0899],\n",
       "         [ 0.0869, -0.0065,  0.0500,  ..., -0.0270, -0.0783,  0.1198],\n",
       "         [ 0.0837,  0.0108,  0.0418,  ...,  0.0195, -0.0666,  0.0272]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " torch.Size([22, 4]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 enc_input_dim = 4, \n",
    "                 encoder_layers = 5,\n",
    "                 encoder_max_width = 512,\n",
    "                 dropout = True,\n",
    "                 dropout_rate = 0.5,\n",
    "                 latent_space_dim = 4):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "        \n",
    "        encoder_layers_width = [neurons for neurons in range(encoder_max_width, latent_space_dim, -int(encoder_max_width/encoder_layers))]\n",
    "        encoder_layers_width.insert(0, enc_input_dim)\n",
    "        \n",
    "        encoder_layers = []\n",
    "        \n",
    "        for i in range(len(encoder_layers_width) - 1):\n",
    "            \n",
    "            input_dim = encoder_layers_width[i]\n",
    "            output_dim = encoder_layers_width[i + 1]\n",
    "            \n",
    "            encoder_layers.append(nn.Linear(input_dim, output_dim))\n",
    "            \n",
    "            if i != len(encoder_layers_width) - 2:\n",
    "                encoder_layers.append(nn.LeakyReLU())\n",
    "                if dropout:\n",
    "                    encoder_layers.append(nn.Dropout(dropout_rate))\n",
    "                \n",
    "        self.Encoder = nn.Sequential(*encoder_layers)\n",
    "        \n",
    "        self.fc_mu = nn.Linear(output_dim, latent_space_dim)\n",
    "        self.fc_logvar = nn.Linear(output_dim, latent_space_dim)\n",
    "        \n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Implementa il trick della rielaborazione per campionare dallo spazio latente.\n",
    "        Args:\n",
    "            mu (torch.Tensor): Media della distribuzione latente (dimensione: batch_size x latent_dim).\n",
    "            logvar (torch.Tensor): Log-varianza della distribuzione latente (dimensione: batch_size x latent_dim).\n",
    "        Returns:\n",
    "            z (torch.Tensor): Campione dallo spazio latente (dimensione: batch_size x latent_dim).\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)  # Calcola lo scarto quadratico medio\n",
    "        epsilon = torch.randn_like(std)  # Campiona da una distribuzione normale standard\n",
    "        z = mu + epsilon * std  # Applica il trick della rielaborazione\n",
    "        return z\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        mu, log_var = self.fc_mu(x), self.fc_logvar(x)\n",
    "        trick = self.reparameterize(mu, log_var)\n",
    "        \n",
    "        return mu, log_var, x, trick.shape\n",
    "        \n",
    "        \n",
    "vae = VariationalAutoEncoder()\n",
    "vae(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073b856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
