{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca59bdf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:17:40.880211Z",
     "start_time": "2024-12-07T13:17:39.488947Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf5834b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:17:41.371095Z",
     "start_time": "2024-12-07T13:17:41.339471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    \n",
    "print(f'Actual device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7647be8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:17:41.932597Z",
     "start_time": "2024-12-07T13:17:41.917283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = load_iris()['data']\n",
    "X\n",
    "min_max = MinMaxScaler()\n",
    "X = min_max.fit_transform(X)\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b083ac9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:17:42.722691Z",
     "start_time": "2024-12-07T13:17:42.713583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4])\n",
      "tensor([[0.2222, 0.7083, 0.0847, 0.1250],\n",
      "        [0.9444, 0.4167, 0.8644, 0.9167],\n",
      "        [0.0833, 0.4583, 0.0847, 0.0417],\n",
      "        [0.6111, 0.4167, 0.8136, 0.8750],\n",
      "        [0.5000, 0.2500, 0.7797, 0.5417],\n",
      "        [0.2222, 0.6250, 0.0678, 0.0833],\n",
      "        [0.2222, 0.7500, 0.0847, 0.0833],\n",
      "        [0.6111, 0.4167, 0.7119, 0.7917],\n",
      "        [0.5556, 0.3333, 0.6949, 0.5833],\n",
      "        [0.5000, 0.4167, 0.6610, 0.7083],\n",
      "        [0.3611, 0.2917, 0.5424, 0.5000],\n",
      "        [0.4167, 0.3333, 0.6949, 0.9583],\n",
      "        [0.6667, 0.5417, 0.7966, 0.8333],\n",
      "        [0.1111, 0.5000, 0.1017, 0.0417],\n",
      "        [0.5278, 0.3333, 0.6441, 0.7083],\n",
      "        [0.0833, 0.6667, 0.0000, 0.0417],\n",
      "        [0.1667, 0.4583, 0.0847, 0.0000],\n",
      "        [0.5833, 0.5000, 0.5932, 0.5833],\n",
      "        [0.1944, 0.5833, 0.0847, 0.0417],\n",
      "        [0.8056, 0.6667, 0.8644, 1.0000],\n",
      "        [0.5833, 0.2917, 0.7288, 0.7500],\n",
      "        [0.8333, 0.3750, 0.8983, 0.7083],\n",
      "        [0.2778, 0.7083, 0.0847, 0.0417],\n",
      "        [0.6111, 0.3333, 0.6102, 0.5833],\n",
      "        [0.3333, 0.9167, 0.0678, 0.0417],\n",
      "        [0.0833, 0.5000, 0.0678, 0.0417],\n",
      "        [0.1944, 0.5417, 0.0678, 0.0417],\n",
      "        [0.1389, 0.4167, 0.0678, 0.0833],\n",
      "        [0.5556, 0.5833, 0.7797, 0.9583],\n",
      "        [0.0278, 0.3750, 0.0678, 0.0417],\n",
      "        [0.0000, 0.4167, 0.0169, 0.0000],\n",
      "        [0.1944, 0.6667, 0.0678, 0.0417]])\n"
     ]
    }
   ],
   "source": [
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype = torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "dataset = IrisDataset(X)\n",
    "dataloader = DataLoader(dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(f'{batch.shape}\\n{batch}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fecc5c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:17:43.390420Z",
     "start_time": "2024-12-07T13:17:43.385638Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in dataloader:\n",
    "    batch = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f9d3eae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:28:55.647912Z",
     "start_time": "2024-12-07T13:28:55.578484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (8): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers = 12\n",
    "latent_space = 8\n",
    "\n",
    "\n",
    "layers_list = []\n",
    "last_layer = int(math.log2(latent_space))\n",
    "last_layer\n",
    "\n",
    "for idx, i in enumerate(range(n_layers, last_layer, -1)):\n",
    "    input_dim = i\n",
    "    output_dim = i - 1\n",
    "    if input_dim != last_layer:\n",
    "        layers_list.append(nn.Sequential(nn.Linear(2**input_dim, 2**output_dim), nn.LeakyReLU(), nn.Dropout()))\n",
    "nn.Sequential(*layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd30e3f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:43:54.037235Z",
     "start_time": "2024-12-07T13:43:54.025000Z"
    }
   },
   "outputs": [],
   "source": [
    "input_features = 4  \n",
    "n_layers = 10       \n",
    "latent_space_dim = 8\n",
    "dropout_rate = 0.5  \n",
    "\n",
    "max_neurons = 2 ** n_layers\n",
    "\n",
    "layers_list = []\n",
    "\n",
    "layers_list.append(nn.Sequential(\n",
    "    nn.Linear(input_features, max_neurons),\n",
    "    nn.LeakyReLU(negative_slope=0.01),\n",
    "    nn.Dropout(p=dropout_rate)\n",
    "))\n",
    "\n",
    "current_dim = max_neurons\n",
    "while current_dim > latent_space_dim:\n",
    "    next_dim = current_dim // 2\n",
    "    layers_list.append(nn.Sequential(\n",
    "        nn.Linear(current_dim, next_dim),\n",
    "        nn.LeakyReLU(negative_slope=0.01),\n",
    "        nn.Dropout(p=dropout_rate)\n",
    "    ))\n",
    "    current_dim = next_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "370c1312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T13:57:48.885710Z",
     "start_time": "2024-12-07T13:57:48.860695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3428, -0.5308],\n",
       "         [-0.5442, -0.3724],\n",
       "         [-0.2604, -0.5979],\n",
       "         [-0.2742, -0.5854],\n",
       "         [-0.2871, -0.5766],\n",
       "         [-0.2587, -0.5979],\n",
       "         [-0.2604, -0.5979],\n",
       "         [-0.5520, -0.3663],\n",
       "         [-0.3171, -0.5528],\n",
       "         [-0.2604, -0.5979],\n",
       "         [-0.3853, -0.4974],\n",
       "         [-0.5582, -0.3598],\n",
       "         [-0.2589, -0.5979],\n",
       "         [-0.2604, -0.5979],\n",
       "         [-0.4109, -0.4783],\n",
       "         [-0.2604, -0.5979],\n",
       "         [-0.2604, -0.5979],\n",
       "         [-0.3733, -0.5065],\n",
       "         [-0.2604, -0.5979],\n",
       "         [-0.2604, -0.5979],\n",
       "         [-0.4542, -0.4424],\n",
       "         [-0.3166, -0.5532]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[0.1768, 0.1684],\n",
       "         [0.4561, 0.1976],\n",
       "         [0.0613, 0.1585],\n",
       "         [0.0813, 0.1590],\n",
       "         [0.0986, 0.1622],\n",
       "         [0.0597, 0.1571],\n",
       "         [0.0613, 0.1585],\n",
       "         [0.4669, 0.1987],\n",
       "         [0.1403, 0.1663],\n",
       "         [0.0613, 0.1585],\n",
       "         [0.2357, 0.1745],\n",
       "         [0.4763, 0.1981],\n",
       "         [0.0599, 0.1573],\n",
       "         [0.0613, 0.1585],\n",
       "         [0.2707, 0.1792],\n",
       "         [0.0613, 0.1585],\n",
       "         [0.0613, 0.1585],\n",
       "         [0.2193, 0.1725],\n",
       "         [0.0613, 0.1585],\n",
       "         [0.0613, 0.1585],\n",
       "         [0.3316, 0.1838],\n",
       "         [0.1395, 0.1663]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.3891, -0.3830],\n",
       "         [-0.0866, -0.1934],\n",
       "         [-0.5160, -0.4582],\n",
       "         [-0.4929, -0.4470],\n",
       "         [-0.4755, -0.4332],\n",
       "         [-0.5167, -0.4612],\n",
       "         [-0.5160, -0.4582],\n",
       "         [-0.0749, -0.1862],\n",
       "         [-0.4301, -0.4053],\n",
       "         [-0.5160, -0.4582],\n",
       "         [-0.3252, -0.3431],\n",
       "         [-0.0633, -0.1822],\n",
       "         [-0.5166, -0.4609],\n",
       "         [-0.5160, -0.4582],\n",
       "         [-0.2883, -0.3178],\n",
       "         [-0.5160, -0.4582],\n",
       "         [-0.5160, -0.4582],\n",
       "         [-0.3428, -0.3547],\n",
       "         [-0.5160, -0.4582],\n",
       "         [-0.5160, -0.4582],\n",
       "         [-0.2207, -0.2791],\n",
       "         [-0.4310, -0.4058]], grad_fn=<AddmmBackward0>),\n",
       " torch.Size([22, 2]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 enc_input_dim = 4, \n",
    "                 encoder_layers = 5,\n",
    "                 dropout_rate = 0.5,\n",
    "                 latent_space_dim = 2):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "        \n",
    "        max_neurons = 2 ** encoder_layers\n",
    "\n",
    "        encoder_layers_list = [\n",
    "            nn.Linear(enc_input_dim, max_neurons),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        ]\n",
    "        \n",
    "        current_dim = max_neurons\n",
    "        while current_dim > latent_space_dim:\n",
    "            next_dim = current_dim // 2\n",
    "            encoder_layers_list.extend(nn.Sequential(\n",
    "                nn.Linear(current_dim, next_dim),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ))\n",
    "            current_dim = next_dim\n",
    "        \n",
    "        encoder_layers_list.append(nn.Linear(current_dim, latent_space_dim))\n",
    "\n",
    "        self.Encoder = nn.Sequential(*encoder_layers_list)\n",
    "        \n",
    "        self.fc_mu = nn.Linear(next_dim, latent_space_dim)\n",
    "        self.fc_logvar = nn.Linear(next_dim, latent_space_dim)\n",
    "        \n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Implementa il trick della rielaborazione per campionare dallo spazio latente.\n",
    "        Args:\n",
    "            mu (torch.Tensor): Media della distribuzione latente (dimensione: batch_size x latent_dim).\n",
    "            logvar (torch.Tensor): Log-varianza della distribuzione latente (dimensione: batch_size x latent_dim).\n",
    "        Returns:\n",
    "            z (torch.Tensor): Campione dallo spazio latente (dimensione: batch_size x latent_dim).\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)  # Calcola lo scarto quadratico medio\n",
    "        epsilon = torch.randn_like(std)  # Campiona da una distribuzione normale standard\n",
    "        z = mu + epsilon * std  # Applica il trick della rielaborazione\n",
    "        return z\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        mu, log_var = self.fc_mu(x), self.fc_logvar(x)\n",
    "        trick = self.reparameterize(mu, log_var)\n",
    "        \n",
    "        return mu, log_var, x, trick.shape\n",
    "        \n",
    "        \n",
    "vae = VariationalAutoEncoder()\n",
    "vae(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073b856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
